# Basic Chat Completion with Azure Inference SDK in Python

This article shows you how to perform a basic chat completion using the Azure Inference SDK in Python. You will set up your environment, install required dependencies, and run a sample script that demonstrates how to interact with Azure's chat completion API.

## Prerequisites

- Python 3.8 or later installed on your system.
- An Azure AI resource with endpoint and key.
- Access to a terminal or command prompt.

## What you'll learn

- How to create a Python virtual environment.
- How to install the Azure Inference SDK and required libraries.
- How to set environment variables for authentication.
- How to use the Azure Inference SDK to send chat messages and receive responses.
- How to map OpenAI ChatCompletion API parameters to Azure Inference API.

---

## 1. Install Dependencies

Set up a Python virtual environment and install the required libraries.

### Windows

1. Open **Command Prompt**.
2. Run the following commands:

    ```cmd
    python -m venv .venv
    .venv\Scripts\activate
    pip install azure-ai-inference==1.0.0b9 azure-core==1.33.0 azure-identity==1.21.0 azure-storage-blob==12.25.1 azure-ai-projects==1.0.0b9
    ```

### Linux/macOS

1. Open **Terminal**.
2. Run the following commands:

    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    pip install azure-ai-inference==1.0.0b9 azure-core==1.33.0 azure-identity==1.21.0 azure-storage-blob==12.25.1 azure-ai-projects==1.0.0b9
    ```

---

## 2. Set Environment Variables

Set the following environment variables with your Azure AI resource values.

- `AZURE_AI_CHAT_ENDPOINT`: Your Azure AI endpoint URL.
- `AZURE_AI_CHAT_KEY`: Your Azure AI key.

### Windows

```cmd
set AZURE_AI_CHAT_ENDPOINT=https://<your-endpoint>.openai.azure.com/
set AZURE_AI_CHAT_KEY=<your-key>
```

### Linux/macOS

```bash
export AZURE_AI_CHAT_ENDPOINT=https://<your-endpoint>.openai.azure.com/
export AZURE_AI_CHAT_KEY=<your-key>
```

Replace `<your-endpoint>` and `<your-key>` with your actual values.

---

## 3. OpenAI to Azure Inference Parameter Mapping

| OpenAI ChatCompletion API | Azure Inference API (Python SDK) |
|--------------------------|-----------------------------------|
| `model`                  | Set in Azure deployment, not in code |
| `messages`               | `messages` (list of `SystemMessage`, `UserMessage`, `AssistantMessage`) |
| `temperature`            | `temperature` (optional, in `complete()` method) |
| `max_tokens`             | `max_tokens` (optional, in `complete()` method) |
| `top_p`                  | `top_p` (optional, in `complete()` method) |
| `n`                      | `n` (optional, in `complete()` method) |
| `stop`                   | `stop` (optional, in `complete()` method) |

---

## 4. Main Code Components Explained

The sample code consists of the following main components:

- **Environment Variable Retrieval**: Reads the endpoint and key from environment variables for authentication.
- **Client Initialization**: Creates a `ChatCompletionsClient` using the endpoint and key.
- **Message Construction**: Builds a list of messages using `SystemMessage`, `UserMessage`, and `AssistantMessage` to represent the conversation.
- **Chat Completion Request**: Sends the messages to the Azure Inference API and receives a response.
- **Conversation History**: Appends previous responses to the message list to maintain context across turns.

---

## 5. Complete Code Example

Save the following code as `chat_completion.py`:

```python
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage
from azure.core.credentials import AzureKeyCredential

def sample_chat_completions_with_history():
    try:
        endpoint = os.environ["AZURE_AI_CHAT_ENDPOINT"]
        key      = os.environ["AZURE_AI_CHAT_KEY"]
    except KeyError:
        print("Missing AZURE_AI_CHAT_ENDPOINT or AZURE_AI_CHAT_KEY")
        exit(1)

    client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))

    # First turn
    messages = [
        SystemMessage("You are an AI assistant that helps people find information. Replies must be â‰¤2 sentences."),
        UserMessage("What year was construction of the international space station mostly done?")
    ]
    response = client.complete(messages=messages)
    print(response.choices[0].message.content)

    # Second turn (history included)
    messages.append(AssistantMessage(response.choices[0].message.content))
    messages.append(UserMessage("And what was the estimated cost to build it?"))
    response = client.complete(messages=messages)
    print(response.choices[0].message.content)

if __name__ == "__main__":
    sample_chat_completions_with_history()
```

---

## 6. Run the Example Code

1. Activate your virtual environment if not already active.
2. Ensure your environment variables are set.
3. Run the script:

    ```bash
    python chat_completion.py
    ```

You should see the assistant's responses printed to the console.

---

## 7. Next Steps

- [Azure Inference SDK Documentation](https://learn.microsoft.com/azure/ai-services/inference/)
- [Azure OpenAI Service Documentation](https://learn.microsoft.com/azure/ai-services/openai/)
- [Azure AI Python SDK Reference](https://pypi.org/project/azure-ai-inference/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat)

Explore additional parameters such as `temperature`, `max_tokens`, and `top_p` in the `complete()` method to customize responses.